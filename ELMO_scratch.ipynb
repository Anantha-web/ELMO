{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJytBo8QNIkr",
        "outputId": "b3dba054-8c80-4b26-de4c-e1e9e5090a0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/user/Desktop/elmo/anlp-assgn2-data\n",
            "ELMO_scratch.ipynb  readme.txt           yelp-subset.test.csv\n",
            "glove.txt           yelp-subset.dev.csv  yelp-subset.train.csv\n"
          ]
        }
      ],
      "source": [
        "%cd \"/home/user/Desktop/elmo/anlp-assgn2-data/\"\n",
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "T86ZhQSvNZOu"
      },
      "outputs": [],
      "source": [
        "#imports  \n",
        "import pandas as pd\n",
        "import re\n",
        "import torch#\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Hn306Z13Nnap"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(55000, 2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_90554/1588324648.py:32: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  data['text'] = data['text'].str.replace(\"[0-9]\", \" \")\n"
          ]
        }
      ],
      "source": [
        "train = pd.read_csv('yelp-subset.train.csv', sep='\\t', header=None)\n",
        "test = pd.read_csv('yelp-subset.test.csv', sep='\\t', header=None)\n",
        "\n",
        "\n",
        "train['label'] = train[0].apply(lambda x: x.split(',')[0])\n",
        "train['text'] = train[0].apply(lambda x: x.split(',', 1)[1])\n",
        "# removes 0 col \n",
        "train = train.drop(columns=[0])\n",
        "train = train.iloc[1: , :]\n",
        "test['label'] = test[0].apply(lambda x: x.split(',')[0])\n",
        "test['text'] = test[0].apply(lambda x: x.split(',', 1)[1])\n",
        "test = test.drop(columns=[0])\n",
        "test = test.iloc[1: , :]\n",
        "\n",
        "data = pd.concat([train, test])\n",
        "\n",
        "#cleaning the data\n",
        "print(data.shape)\n",
        "\n",
        "data['text'] = data['text'].apply(lambda x: re.sub(r'http\\S+', '', x))\n",
        "\n",
        "\n",
        "punctuation = '!\"#$%&()*+-/:;<=>?@[\\\\]^_`{|}~'\n",
        "\n",
        "data['text'] = data['text'].apply(lambda x: ''.join(ch for ch in x if ch not in set(punctuation)))\n",
        "\n",
        "\n",
        "# convert text to lowercase\n",
        "data['text'] = data['text'].str.lower()\n",
        "\n",
        "\n",
        "# remove numbers\n",
        "data['text'] = data['text'].str.replace(\"[0-9]\", \" \")\n",
        "\n",
        "\n",
        "# remove whitespaces\n",
        "data['text'] = data['text'].apply(lambda x:' '.join(x.split()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "0pfwxdJBlJCz"
      },
      "outputs": [],
      "source": [
        "# truncate the dataset\n",
        "new_data = data.iloc[:1000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "468joh-NOZ0l",
        "outputId": "1af2ca4e-f2b9-412f-a31f-769ee61b3001"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "11308\n",
            "9224\n",
            "9224\n",
            "['<sos>', 'of', 'course,', 'at', \"mike's\", 'you', 'would', 'probably', 'be', 'stampeded,', 'but', \"that's\", 'another', 'issue', 'entirely', '<eos>']\n"
          ]
        }
      ],
      "source": [
        "# print one sentence from the dataset 'text'\n",
        "# for every sentence in the text on data set, extract the sentence based on full stop\n",
        "# and store each sentence in a sentences dataframe                                                                                                                                                                                                                                                                                                      \n",
        "sentences = []\n",
        "\n",
        "for s in new_data['text']:\n",
        "    sentences.append(s.split('.'))\n",
        "\n",
        "\n",
        "# flatten the list of lists\n",
        "sentences = [y for x in sentences for y in x]\n",
        "print(len(sentences))\n",
        "\n",
        "# remove empty sentences\n",
        "sentences = [s for s in sentences if len(s) > 0]\n",
        "print(len(sentences))\n",
        "\n",
        "# for every sentence in the sentences list, attach <eos> and <sos> tags\n",
        "sentences = ['<sos> ' + s + ' <eos>' for s in sentences]\n",
        "\n",
        "\n",
        "new_sentences= []\n",
        "words = []\n",
        "for s in sentences:\n",
        "    new_sentences.append(s.split())\n",
        "\n",
        "print(len(new_sentences))\n",
        "sentences = new_sentences\n",
        "print(sentences[10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXk5Jk-2UTxo",
        "outputId": "25696406-d1f0-4012-901d-ca04abbd8f1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12594\n"
          ]
        }
      ],
      "source": [
        "#creating a index od each word. ex: she , he padd word[1]= she or word[2]= he...we printing vocab length at the end.\n",
        "vocb = {}\n",
        "for sentence in sentences:\n",
        "    for word in sentence:\n",
        "        if word not in vocb:\n",
        "            vocb[word] = 1\n",
        "        else:\n",
        "            vocb[word] += 1\n",
        "\n",
        "\n",
        "word_to_idx = {word: i for i, word in enumerate(vocb)}\n",
        "idx_to_word = {word_to_idx[word]: word for word in word_to_idx}\n",
        "print(len(vocb))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "gzoaHOQbXD-7"
      },
      "outputs": [],
      "source": [
        "#creats embedding dictionary. it is a dictionary of words and their corresponding vectors.\n",
        "import numpy as np\n",
        "embeddings_dict = {}\n",
        "word_dict={}\n",
        "with open(\"glove.txt\", 'r') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        vector = np.asarray(values[1:], \"float32\")\n",
        "        embeddings_dict[word] = vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "h220GiSqXKDi"
      },
      "outputs": [],
      "source": [
        "\n",
        "import random\n",
        "\n",
        "etag = random.randint(1,10)\n",
        "stag = random.randint(1,10)\n",
        "\n",
        "eos_tag = [etag for i in range(50)]\n",
        "sos_tag = [stag for i in range(50)]\n",
        "\n",
        "# word and corrsponding vector\n",
        "def find_embedding(word):\n",
        "  if(word==\"<sos>\"):\n",
        "    return sos_tag\n",
        "  elif(word==\"<eos>\"):\n",
        "    return eos_tag\n",
        "\n",
        "  vector=[0 for i in range(50)]\n",
        "  try:\n",
        "    vector=embeddings_dict[word]\n",
        "\n",
        "  except:\n",
        "    return vector\n",
        "  return vector\n",
        "\n",
        "# \n",
        "def give_embedding(x):\n",
        "  (batch_size, seq_len,temp) = x.shape\n",
        "  ans = torch.zeros(batch_size, seq_len, 50)\n",
        "  for i in range(batch_size):\n",
        "    for j in range(seq_len):\n",
        "      emb = find_embedding(idx_to_word[x[i][j].item()])\n",
        "      for k in range(len(emb)):\n",
        "        ans[i][j][k] = float(emb[k])\n",
        "  return ans\n",
        "\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-i3btc_Xq95",
        "outputId": "8541a5ed-b00f-4357-d011-bd6b91c885b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/user/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:83: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 10010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:109.)\n",
            "  return torch._C._cuda_getDeviceCount() > 0\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "qsS7Z_0e1lVs"
      },
      "outputs": [],
      "source": [
        "# \n",
        "class ELMO(nn.Module):\n",
        "    def __init__(self, hidden_size, req_emb_size,input_size,vocb_size):\n",
        "        super(ELMO, self).__init__()\n",
        "        self.vocb_size = vocb_size\n",
        "        self.Bi1 = nn.LSTM(input_size, hidden_size, bidirectional = True, batch_first=True )\n",
        "        self.Bi2 = nn.LSTM(hidden_size*2, hidden_size, bidirectional = True, batch_first=True )\n",
        "        self.linear1 = nn.Linear(hidden_size*2, vocb_size)\n",
        "        \n",
        "        # keeping weights\n",
        "        self.w1 =  torch.nn.Parameter(torch.randn(50,req_emb_size))\n",
        "        self.w2 =  torch.nn.Parameter(torch.randn(2*hidden_size,req_emb_size))\n",
        "        self.w3 =  torch.nn.Parameter(torch.randn(2*hidden_size,req_emb_size))\n",
        "        \n",
        "        \n",
        "\n",
        "    # \n",
        "    def forward(self, x):\n",
        "        glove_emb = give_embedding(x)\n",
        "        \n",
        "        Bi1out,_ = self.Bi1(glove_emb)\n",
        "        Bi2out,_ = self.Bi2(Bi1out)\n",
        "        last_word = Bi2out[:,-1,:] # last word of the sentence\n",
        "        out = self.linear1(last_word)\n",
        "        out = F.softmax(out, dim=1)\n",
        "\n",
        "        return out\n",
        "\n",
        "    # will give sentence embedding\n",
        "    def give_elmo(self,x):\n",
        "      glove_emb = give_embedding(x)\n",
        "      Bi1out,_ = self.Bi1(glove_emb)\n",
        "      Bi2out,_ = self.Bi2(Bi1out)\n",
        "\n",
        "      t1 = torch.matmul(glove_emb, self.w1)\n",
        "      t2 = torch.matmul(Bi1out, self.w2)\n",
        "      t3 = torch.matmul(Bi2out, self.w3)\n",
        "\n",
        "      temp1 = torch.add(t2, t3)\n",
        "      temp2 = torch.add(t1, temp1)\n",
        "\n",
        "      return (temp2) #embedding of the sentence\n",
        "      \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ryqaa0UBfcdS"
      },
      "outputs": [],
      "source": [
        "# splitting into batches\n",
        "batches = [[] for i in range(0,1000)]\n",
        "import copy\n",
        "train_elmo_x = []\n",
        "train_elmo_y = []\n",
        "\n",
        "for sentence in sentences:\n",
        "  words = []\n",
        "  for word in sentence:\n",
        "    if(len(words)==0):\n",
        "      words.append(word)\n",
        "    else:\n",
        "      batches[len(words)].append((copy.deepcopy(words), word))\n",
        "      train_elmo_x.append(copy.deepcopy(words))\n",
        "      train_elmo_y.append(word)\n",
        "      words.append(word)\n",
        "batches = [b for b in batches if len(b) > 0]\n",
        "\n",
        "elmo = ELMO(100,100,50, len(vocb)) # hidden size, required embedding size, glove embedding size, vocab size\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(elmo.parameters(), lr=1e-2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "wRjwWWh3rYjg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 1 LOSS: 1482.2344284057617\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mCanceled future for execute_request message before replies were done"
          ]
        }
      ],
      "source": [
        "for epoch in range(3):\n",
        "  total_loss = 0\n",
        "  batch_num = 0\n",
        "  for batch in batches:\n",
        "    batch_size = len(batch)\n",
        "    seq_len = len(batch[0][0])\n",
        "    train_x = torch.zeros(batch_size, seq_len, 1)\n",
        "    train_y = torch.zeros(batch_size, 1)\n",
        "\n",
        "    for i, (x,y) in enumerate(batch):\n",
        "      \n",
        "      index_form = []\n",
        "      for word in x:\n",
        "        index_form.append(word_to_idx[word])\n",
        "      for j in range(len(index_form)):\n",
        "        train_x[i][j] = index_form[j]\n",
        "      train_y[i] = word_to_idx[y]\n",
        "\n",
        "\n",
        "    out = elmo(train_x)\n",
        "    \n",
        "\n",
        "    loss = criterion(out, train_y.squeeze(dim=1).type(torch.LongTensor))\n",
        "    total_loss +=loss.item()\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward(retain_graph=True)\n",
        "    optimizer.step()\n",
        "    batch_num+=1\n",
        "\n",
        "  print(\"EPOCH: \" + str(epoch+1) + \" LOSS: \" + str(total_loss))\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ITaXTS3Wf7n9"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'torch' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m/home/user/Desktop/elmo/anlp-assgn2-data/ELMO_scratch.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/user/Desktop/elmo/anlp-assgn2-data/ELMO_scratch.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m torch\u001b[39m.\u001b[39msave(elmo, \u001b[39m\"\u001b[39m\u001b[39m/home/user/Desktop/elmo/anlp-assgn2-data/elmo-v1.pt\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ],
      "source": [
        "torch.save(elmo, \"/home/user/Desktop/elmo/anlp-assgn2-data/elmo-v1.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LA3hCYsfehtU"
      },
      "source": [
        "## classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rrm5262jeg5B"
      },
      "outputs": [],
      "source": [
        "elmo = torch.load(\"/home/user/Desktop/elmo/anlp-assgn2-data/elmo-v1.pt\")\n",
        "\n",
        "def generate_elmo(sentence):\n",
        "  batch_size = 1\n",
        "  seq_len = len(sentence)\n",
        "  to_feed = torch.zeros(batch_size, seq_len, 1)\n",
        "    \n",
        "  for j in range(seq_len):\n",
        "    to_feed[0][j] = sentence[j]\n",
        "\n",
        "  \n",
        "  return elmo.give_elmo(to_feed)\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HFXD3FzUiT-9"
      },
      "outputs": [],
      "source": [
        "class DOWN(nn.Module):\n",
        "    def __init__(self, emb_size):\n",
        "        super(DOWN, self).__init__()\n",
        "        self.linear1 = nn.Linear(emb_size, 300)\n",
        "        self.linear2 = nn.Linear(300, 5)\n",
        "\n",
        "      \n",
        "\n",
        "    def forward(self, x):\n",
        "        elmo_emb = generate_elmo(x).squeeze(dim=0)\n",
        "        elmo_emb = torch.flatten(elmo_emb)\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        out = self.linear1(elmo_emb)\n",
        "        out = F.relu(out)\n",
        "\n",
        "        out = self.linear2(out)\n",
        "        out = F.softmax(out, dim=0)\n",
        "\n",
        "        return out\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wqMNwqwKI35e"
      },
      "outputs": [],
      "source": [
        "down = DOWN(3000)\n",
        "criterion1 = nn.CrossEntropyLoss()\n",
        "optimizer1 = optim.SGD(down.parameters(), lr=1e-2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TcrkIicCv5Cj"
      },
      "outputs": [],
      "source": [
        "# test set\n",
        "x=[]\n",
        "y=[]\n",
        "#iterate over the rows of the dataframe to select the text and label\n",
        "limit = 30\n",
        "for index, row in new_data.iterrows():\n",
        "    \n",
        "    text = row['text'].replace('.',' ')\n",
        "    words = text.split()[:limit]\n",
        "    \n",
        "    x.append(words)\n",
        "    y.append(int(row['label']))\n",
        "\n",
        "# for each x if the length is less than limit, add padding\n",
        "for i in range(len(x)):\n",
        "    if len(x[i]) < limit:\n",
        "        for j in range(limit-len(x[i])):\n",
        "            x[i].append('pad')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fN99u_svHJQd",
        "outputId": "b8573b6a-5a39-4636-c4d1-92fa8154d9ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 0Accuracy: 0.208\n",
            "EPOCH: 1Accuracy: 0.199\n",
            "EPOCH: 2Accuracy: 0.198\n",
            "EPOCH: 3Accuracy: 0.197\n",
            "EPOCH: 4Accuracy: 0.199\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(5):\n",
        "  \n",
        "  req = 0\n",
        "  for i in range(len(x)):\n",
        "    temp_x = torch.zeros(30)\n",
        "    for j,word in enumerate(x[i]):\n",
        "      temp_x[j]= (word_to_idx[word])\n",
        "      \n",
        "\n",
        "    \n",
        "    out = down(temp_x)\n",
        "    amma = out.argmax().item()\n",
        "    if(amma == int(y[i])):\n",
        "      req+=1\n",
        "    temp_y = torch.zeros(1)\n",
        "    temp_y[0] = int(y[i])\n",
        "    \n",
        "\n",
        "    loss = criterion1(out, temp_y.squeeze(dim=0).type(torch.LongTensor))\n",
        "    optimizer1.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer1.step()\n",
        "\n",
        "  print(\"EPOCH: \" + str(epoch) + \"Accuracy: \" + str(req/len(x)))\n",
        "  \n",
        "\n",
        "\n",
        "  \n",
        "  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71XLBvBLR0Fx",
        "outputId": "497aa660-9d19-46a2-e3dc-035f460ead75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy is : 20.1\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[  0,   0,   1,   1, 185],\n",
              "       [  0,   0,   0,   1, 208],\n",
              "       [  0,   0,   2,   0, 211],\n",
              "       [  0,   0,   1,   3, 190],\n",
              "       [  0,   0,   1,   0, 196]])"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "\n",
        "total = len(x)\n",
        "req = 0\n",
        "\n",
        "a = []\n",
        "b=[]\n",
        "for i in range(len(x)):\n",
        "  temp_x = torch.zeros(30)\n",
        "  for j,word in enumerate(x[i]):\n",
        "    temp_x[j]= (word_to_idx[word])\n",
        "    \n",
        "\n",
        "  \n",
        "  out = down(temp_x)\n",
        "  out = out.argmax().item()\n",
        "  if(out == int(y[i])):\n",
        "    req+=1\n",
        "  a.append(out)\n",
        "  b.append(int(y[i]))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"Accuracy is : \" + str(req*100/total))\n",
        "\n",
        "a = np.array(a)\n",
        "b = np.array(b)\n",
        "metrics.confusion_matrix(b, a)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FAFixUOUVi5",
        "outputId": "f63f7770-6cf3-4b92-d29e-a57f93219237"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       187\n",
            "           1       0.00      0.00      0.00       209\n",
            "           2       0.40      0.01      0.02       213\n",
            "           3       0.60      0.02      0.03       194\n",
            "           4       0.20      0.99      0.33       197\n",
            "\n",
            "    accuracy                           0.20      1000\n",
            "   macro avg       0.24      0.20      0.08      1000\n",
            "weighted avg       0.24      0.20      0.07      1000\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn import metrics\n",
        "print(metrics.classification_report(b, a))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
